ggplot() + geom_sf(data = na.omit(tracts17), aes(fill = incomeContext)) +
scale_fill_manual(values = c("#25CB10", "#FA7800"), name="Income Context") +
labs(title = "Income Context") +
mapTheme() + theme(legend.position="bottom"))
knitr::opts_chunk$set(echo = TRUE)
tracts20 <-
get_acs(geography = "tract",
variables = c("B25026_001E","B02001_002E",
"B15001_050E","B15001_009E",
"B19013_001E","B25058_001E",
"B06012_002E"),
year=2020, state=42, county=101,
geometry=TRUE, output="wide") %>%
st_transform('ESRI:102728') %>%
rename(TotalPop = B25026_001E,
Whites = B02001_002E,
FemaleBachelors = B15001_050E,
MaleBachelors = B15001_009E,
MedHHInc = B19013_001E,
MedRent = B25058_001E,
TotalPoverty = B06012_002E) %>%
dplyr::select(-NAME, -starts_with("B")) %>%
mutate(pctWhite = ifelse(TotalPop > 0, Whites / TotalPop,0),
pctBachelors = ifelse(TotalPop > 0, ((FemaleBachelors + MaleBachelors) / TotalPop),0),
pctPoverty = ifelse(TotalPop > 0, TotalPoverty / TotalPop, 0),
year = "2020") %>%
dplyr::select(-Whites, -FemaleBachelors, -MaleBachelors, -TotalPoverty)
tracts20 <-
get_acs(geography = "tract", variables = c("B25026_001E","B02001_002E","B19013_001E"),
year=2020, state=42, county=101,
geometry=TRUE, output="wide") %>%
st_transform('ESRI:102728') %>%)
tracts20 <-
get_acs(geography = "tract", variables = c("B25026_001E","B02001_002E","B19013_001E"),
year=2020, state=42, county=101, geometry=TRUE, output="wide")
tracts20 <-
get_acs(geography = "tract", variables = c("B25026_001E","B02001_002E","B19013_001E"),
year=2020, state=42, county=101, geometry=TRUE, output="wide") %>%
st_transform('ESRI:102729') %>%)
tracts20 <-
get_acs(geography = "tract", variables = c("B25026_001E","B02001_002E","B19013_001E"),
year=2020, state=42, county=101, geometry=TRUE, output="wide") %>%
st_transform('ESRI:102729') %>%
rename(TotalPop = B25026_001E,
NumberWhites =B02001_002E,
Median_Income = B19013_001E) %>%
mutate(percentWhite = NumberWhites / TotalPop,
raceContext = ifelse(percentWhite > .5, "Majority White", "Majority Non-White"),
incomeContext = ifelse(Median_Income > 32322, "High Income", "Low Income"))
tracts17 <-
get_acs(geography = "tract", variables = c("B01001_001E","B01001A_001E","B06011_001"),
year = 2017, state=25, county=025, geometry=T, output = "wide") %>%
st_transform('ESRI:102286')  %>%
grid.arrange(ncol = 2,
ggplot() + geom_sf(data = na.omit(tracts20), aes(fill = raceContext)) +
scale_fill_manual(values = c("#25CB10", "#FA7800"), name="Race Context") +
labs(title = "Race Context") +
mapTheme() + theme(legend.position="bottom"),
ggplot() + geom_sf(data = na.omit(tracts17), aes(fill = incomeContext)) +
scale_fill_manual(values = c("#25CB10", "#FA7800"), name="Income Context") +
labs(title = "Income Context") +
mapTheme() + theme(legend.position="bottom"))
tracts20 <-
get_acs(geography = "tract", variables = c("B25026_001E","B02001_002E","B19013_001E"),
year=2020, state=42, county=101, geometry=TRUE, output="wide") %>%
st_transform('ESRI:102729') %>%
rename(TotalPop = B25026_001E,
NumberWhites =B02001_002E,
Median_Income = B19013_001E) %>%
mutate(percentWhite = NumberWhites / TotalPop,
raceContext = ifelse(percentWhite > .5, "Majority White", "Majority Non-White"),
incomeContext = ifelse(Median_Income > 32322, "High Income", "Low Income"))
grid.arrange(ncol = 2,
ggplot() + geom_sf(data = na.omit(tracts20), aes(fill = raceContext)) +
scale_fill_manual(values = c("#25CB10", "#FA7800"), name="Race Context") +
labs(title = "Race Context") +
mapTheme() + theme(legend.position="bottom"),
ggplot() + geom_sf(data = na.omit(tracts20), aes(fill = incomeContext)) +
scale_fill_manual(values = c("#25CB10", "#FA7800"), name="Income Context") +
labs(title = "Income Context") +
mapTheme() + theme(legend.position="bottom"))
tracts20 <-
get_acs(geography = "tract", variables = c("B25026_001E","B02001_002E","B19013_001E"),
year=2020, state=42, county=101, geometry=TRUE, output="wide") %>%
st_transform('ESRI:102729') %>%
rename(TotalPop = B25026_001E,
NumberWhites =B02001_002E,
Median_Income = B19013_001E) %>%
mutate(percentWhite = NumberWhites / TotalPop,
raceContext = ifelse(percentWhite > .5, "Majority White", "Majority Non-White"),
incomeContext = ifelse(Median_Income > 32322, "High Income", "Low Income"))
grid.arrange(ncol = 2,
ggplot() + geom_sf(data = na.omit(tracts20), aes(fill = raceContext)) +
scale_fill_manual(values = c("#25CB10", "#FA7800"), name="Race Context") +
labs(title = "Race Context") +
mapTheme() + theme(legend.position="bottom"),
ggplot() + geom_sf(data = na.omit(tracts20), aes(fill = incomeContext)) +
scale_fill_manual(values = c("#25CB10", "#FA7800"), name="Income Context") +
labs(title = "Income Context") +
mapTheme() + theme(legend.position="bottom"))
# You can set some global options for knitting chunks
knitr::opts_chunk$set(echo = TRUE)
# Load some libraries
library(tidyverse)
library(tidycensus)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(broom)
library(tufte)
library(rmarkdown)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
# functions and data directory
root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
acs_vars <- c("B01001_001E", # ACS total Pop estimate
"B25002_001E", # Estimate of total housing units
"B25002_003E", # Number of vacant housing units
"B19013_001E", # Median HH Income ($)
"B02001_002E", # People describing themselves as "white alone"
"B06009_006E") # Total graduate or professional degree
acsTractsPHL.2020 <- get_acs(geography = "tract",
year = 2020,
variables = acs_vars,
geometry = TRUE,
state = "PA",
county = "Philadelphia",
output = "wide") %>%
st_transform('ESRI:102729')
nhoods <-
st_read("D:/Upenn/23fall/MUSA5080 Public Policy Analysis/midterm 4-5/studentData.geojson") %>%
st_transform('ESRI:102729')
to_predict <-
nhoods %>%
dplyr::filter(toPredict == 'CHALLENGE') #Select data for later prediction
to_train <-
nhoods %>%
dplyr::filter(toPredict == 'MODELLING') #Select data for training Model
#??
#Philadelphia <-
# read.csv(file.path(root.dir,"/Chapter3_4/phillyHousePriceData_clean.csv"))
# Load crime data
philadelphiCrimes <- read.csv('https://raw.githubusercontent.com/ObjQIAN/MUSA-508-Midterm/main/data/Philadelphia_crime.csv')
# Create sf and select Weapon Violations
philadelphiCrimes.sf <-
philadelphiCrimes %>%
filter(text_general_code == "Weapon Violations",
lat > -1) %>%
dplyr::select(lat, lng) %>%
na.omit() %>%
st_as_sf(coords = c( "lng","lat"), crs = "EPSG:4326") %>%
st_transform('ESRI:102729') %>%
distinct()
# Load 311 data
philadelphia311 <- read.csv('https://phl.carto.com/api/v2/sql?filename=public_cases_fc&format=csv&skipfields=cartodb_id,the_geom,the_geom_webmercator&q=SELECT%20*%20FROM%20public_cases_fc%20WHERE%20requested_datetime%20%3E=%20%272022-01-01%27%20AND%20requested_datetime%20%3C%20%272023-01-01%27') %>%
dplyr::select(lat, lon) %>%
na.omit() %>%
st_as_sf(coords = c("lon", "lat"), crs = 4326, agr = "constant") %>%
st_transform('ESRI:102729')
# ggplot, reorder
# Mapping data
ggplot() +
geom_sf(data = acsTractsPHL.2020, fill = "grey40") +
geom_sf(data = to_train, aes(colour = q5(sale_price)),
show.legend = "point", size = .35) +
scale_colour_manual(values = palette5,
labels=qBr(to_train,"sale_price"),
name="Quintile\nBreaks") +
labs(title="House Sale Price, Philadelphia") +
mapTheme()
# Counts of crime per buffer of house sale
to_train$crimes.Buffer <- to_train %>%
st_buffer(660) %>%
aggregate(mutate(philadelphiCrimes.sf, counter = 1),., sum) %>%
pull(counter)
## Nearest Neighbor Feature
to_train <-
to_train %>%
mutate(
crime_nn1 = nn_function(st_coordinates(to_train),
st_coordinates(philadelphiCrimes.sf), k = 1),
crime_nn2 = nn_function(st_coordinates(to_train),
st_coordinates(philadelphiCrimes.sf), k = 2),
crime_nn3 = nn_function(st_coordinates(to_train),
st_coordinates(philadelphiCrimes.sf), k = 3),
crime_nn4 = nn_function(st_coordinates(to_train),
st_coordinates(philadelphiCrimes.sf), k = 4),
crime_nn5 = nn_function(st_coordinates(to_train),
st_coordinates(philadelphiCrimes.sf), k = 5))
## Plot assault density
ggplot() + geom_sf(data = acsTractsPHL.2020, fill = "grey40") +
stat_density2d(data = data.frame(st_coordinates(philadelphiCrimes.sf)),
aes(X, Y, fill = ..level.., alpha = ..level..),
size = 0.01, bins = 40, geom = 'polygon') +
scale_fill_gradient(low = "#25CB10", high = "#FA7800", name = "Density") +
scale_alpha(range = c(0.00, 0.35), guide = "none") +
labs(title = "Density of WA, PHL") +
mapTheme()
## Home Features cor
st_drop_geometry(to_train) %>%
mutate(Age = 2022 - year_built) %>%
dplyr::select(sale_price, total_livable_area, Age, crimes.Buffer) %>%
filter(sale_price <= 1000000, Age < 500, total_livable_area <10000) %>%
gather(Variable, Value, -sale_price) %>%
ggplot(aes(Value, sale_price)) +
geom_point(size = .5) +
geom_smooth(data = . %>% filter(sale_price >0), method = "lm", se=F, colour = "#FA7800") +
facet_wrap(~Variable, ncol = 3, scales = "free") +
labs(title = "Price as a function of continuous variables") +
plotTheme()
## Crime cor
to_train %>%
st_drop_geometry() %>%
mutate(Age = 2022 - year_built) %>%
dplyr::select(sale_price, starts_with("crime_")) %>%
filter(sale_price <= 1000000) %>%
gather(Variable, Value, -sale_price) %>%
ggplot(aes(Value, sale_price)) +
geom_point(size = .5) +
geom_smooth(data = . %>% filter(sale_price > 0), method = "lm", se=F, colour = "#FA7800") +
facet_wrap(~Variable, nrow = 1, scales = "free") +
labs(title = "Price as a function of continuous variables") +
plotTheme()
# the result above is too similar, So we calculate and compare the R^2 to choose which crime data to use.
# The result shows that crime_nn3 is the best one.
Crime1Reg <- lm(sale_price ~ crime_nn1, data = philly_sub_200k)
summary(Crime1Reg)
Crime2Reg <- lm(sale_price ~ crime_nn2, data = philly_sub_200k)
summary(Crime2Reg)
Crime3Reg <- lm(sale_price ~ crime_nn3, data = philly_sub_200k)
summary(Crime3Reg)
Crime4Reg <- lm(sale_price ~ crime_nn4, data = philly_sub_200k)
summary(Crime4Reg)
Crime5Reg <- lm(sale_price ~ crime_nn5, data = philly_sub_200k)
summary(Crime5Reg)
numericVars <-
select_if(st_drop_geometry(to_train), is.numeric) %>% na.omit()
ggcorrplot(
round(cor(numericVars), 1),
p.mat = cor_pmat(numericVars),
colors = c("#25CB10", "white", "#FA7800"),
type="lower",
insig = "blank") +
labs(title = "Correlation across numeric variables")
#有无穷或遗漏值？
# yet another way to plot the correlation plot using the corrr library
#numericVars %>%
#  correlate() %>%
#  autoplot() +
#  geom_text(aes(label = round(r,digits=2)),size = 2)
philly_sub_200k <- st_drop_geometry(to_train) %>%
filter(sale_price <= 2000000, total_livable_area < 10000, total_livable_area > 0)
cor.test(philly_sub_200k$total_livable_area,
philly_sub_200k$sale_price,
method = "pearson")
ggscatter(philly_sub_200k,
x = "total_livable_area",
y = "sale_price",
add = "reg.line") +
stat_cor(label.y = 2500000)
livingReg <- lm(sale_price ~ total_livable_area, data = philly_sub_200k)
summary(livingReg)
ggscatter(philly_sub_200k,
x = "total_livable_area",
y = "sale_price",
add = "reg.line") +
stat_cor(aes(label = paste(..rr.label.., ..p.label.., sep = "~`,`~")), label.y = 2500000) +
stat_regline_equation(label.y = 2250000)
coefficients(livingReg)
new_total_livable_area = 4000
# "by hand"
-41433.9841  + 88.34939 * new_total_livable_area
# predict() function
predict(livingReg, newdata = data.frame(total_livable_area = 4000))
reg1 <- lm(sale_price ~ ., data = philly_sub_200k %>%
dplyr::select(sale_price, total_livable_area, crime_nn3 ))
summary(reg1)
## Plot of marginal response
effect_plot(reg1, pred = total_livable_area, interval = TRUE, plot.points = TRUE)
## Plot coefficients
plot_summs(reg1, scale = TRUE)
## plot multiple model coeffs
plot_summs(reg1, livingReg)
inTrain <- createDataPartition(
y = paste(to_train$building_code_description, to_train$quality_grade),
p = .60, list = FALSE)
philly.training <- to_train[inTrain,]
philly.test <- to_train[-inTrain,]
reg.training <-
lm(sale_price ~ ., data = as.data.frame(philly.training) %>%
dplyr::select(sale_price, total_livable_area, crimes.Buffer))
philly.test <-
philly.test %>%
mutate(Regression = "Baseline Regression",
sale_price.Predict = predict(reg.training, philly.test),
sale_price.Error = sale_price.Predict - sale_price,
sale_price.AbsError = abs(sale_price.Predict - sale_price),
sale_price.APE = (abs(sale_price.Predict - sale_price)) / sale_price.Predict)%>%
filter(sale_price < 5000000)
# Remove invalid predictions (Maybe need to do this before running the test)
philly.test <-  philly.test[!with(philly.test,is.na(sale_price.Predict)),]
coords <- st_coordinates(philly.test)
neighborList <- knn2nb(knearneigh(coords, 5))
spatialWeights <- nb2listw(neighborList, style="W")
philly.test$lagPrice <- lag.listw(spatialWeights, philly.test$sale_price)
coords.test <-  st_coordinates(philly.test)
neighborList.test <- knn2nb(knearneigh(coords.test, 5))
spatialWeights.test <- nb2listw(neighborList.test, style="W")
ggplot() +
geom_point(data = philly.test, aes(x = lagPrice, y = sale_price), size = 2) +
geom_smooth(data = philly.test, aes(x = lagPrice, y = sale_price), method = "lm", se = F, colour = "#FA7800") +
labs(title = "Price as a function of the spatial lag of price",
x = "Spatial Lag of Price (Mean price of 5 nearest neighbors)",
y = "Sale Price")
philly.test %>%
mutate(lagPriceError = lag.listw(spatialWeights.test, sale_price.Error)) %>%
ggplot()+
geom_point(aes(x =lagPriceError, y =sale_price.Error)) +
geom_smooth(aes(x = lagPriceError, y = sale_price.Error),method = "lm", se=F, colour = "#FA7800") +
labs(title = "Error as a function of the spatial lag of price",
x = "Spatial Lag of Error (Mean error of 5 nearest neighbors)", y = "Sale Price")
moranTest <- moran.mc(philly.test$sale_price.Error,
spatialWeights.test, nsim = 999)
ggplot(as.data.frame(moranTest$res[c(1:999)]), aes(moranTest$res[c(1:999)])) +
geom_histogram(binwidth = 0.01) +
geom_vline(aes(xintercept = moranTest$statistic), colour = "#FA7800",size=1) +
scale_x_continuous(limits = c(-1, 1)) +
labs(title="Observed and permuted Moran's I",
subtitle= "Observed Moran's I in orange",
x="Moran's I",
y="Count") +
plotTheme()
philly.test %>%
as.data.frame() %>%
# Tract is not a good factor here
group_by(census_tract) %>%
summarize(meanPrediction = mean(sale_price.Predict),
meanPrice = mean(sale_price)) %>%
kable() %>%
kable_styling()
reg.nhood <- lm(sale_price ~ ., data = as.data.frame(philly.training) %>%
dplyr::select(census_tract, sale_price,
total_livable_area, crimes.Buffer))
philly.test.nhood <-
philly.test %>%
mutate(Regression = "Neighborhood Effects",
sale_price.Predict = predict(reg.nhood, philly.test),
sale_price.Error = sale_price.Predict- sale_price,
sale_price.AbsError = abs(sale_price.Predict- sale_price),
sale_price.APE = (abs(sale_price.Predict- sale_price)) / sale_price)%>%
filter(sale_price < 5000000)
bothRegressions <-
rbind(
dplyr::select(philly.test, starts_with("sale_price"), Regression, census_tract) %>%
mutate(lagPriceError = lag.listw(spatialWeights.test, sale_price.Error)),
dplyr::select(philly.test.nhood, starts_with("sale_price"), Regression, census_tract) %>%
mutate(lagPriceError = lag.listw(spatialWeights.test, sale_price.Error)))
st_drop_geometry(bothRegressions) %>%
gather(Variable, Value, -Regression, -census_tract) %>%
filter(Variable == "sale_price.AbsError" | Variable == "sale_price.APE") %>%
group_by(Regression, Variable) %>%
summarize(meanValue = mean(Value, na.rm = T)) %>%
spread(Variable, meanValue) %>%
kable()
bothRegressions %>%
dplyr::select(sale_price.Predict, sale_price, Regression) %>%
ggplot(aes(sale_price, sale_price.Predict)) +
geom_point() +
stat_smooth(aes(sale_price, sale_price.Predict),
method = "lm", se = FALSE, size = 1, colour="#FA7800") +
stat_smooth(aes(sale_price.Predict, sale_price),
method = "lm", se = FALSE, size = 1, colour="#25CB10") +
facet_wrap(~Regression) +
labs(title="Predicted sale price as a function of observed price",
subtitle="Orange line represents a perfect prediction; Green line represents prediction") +
plotTheme()
st_drop_geometry(bothRegressions) %>%
group_by(Regression, sale_price) %>%
summarize(mean.MAPE = mean(sale_price.APE, na.rm = TRUE), .groups = "drop") %>%
ungroup() %>%
left_join(philly.test, by = c(#有问题"Name" = "neighborhood")) %>%
st_sf() %>%
ggplot() +
geom_sf(aes(fill = mean.MAPE)) +
geom_sf(data = bothRegressions, colour = "black", size = 0.5) +
facet_wrap(~Regression) +
scale_fill_gradient(low = palette5[1], high = palette5[5],
name = "MAPE") +
labs(title = "Mean test set MAPE by neighborhood") +
mapTheme()
tracts20 <-
get_acs(geography = "tract", variables = c("B25026_001E","B02001_002E","B19013_001E"),
year=2020, state=42, county=101, geometry=TRUE, output="wide") %>%
st_transform('ESRI:102729') %>%
rename(TotalPop = B25026_001E,
NumberWhites =B02001_002E,
Median_Income = B19013_001E) %>%
mutate(percentWhite = NumberWhites / TotalPop,
raceContext = ifelse(percentWhite > .5, "Majority White", "Majority Non-White"),
incomeContext = ifelse(Median_Income > 32322, "High Income", "Low Income"))
grid.arrange(ncol = 2,
ggplot() + geom_sf(data = na.omit(tracts20), aes(fill = raceContext)) +
scale_fill_manual(values = c("#25CB10", "#FA7800"), name="Race Context") +
labs(title = "Race Context") +
mapTheme() + theme(legend.position="bottom"),
ggplot() + geom_sf(data = na.omit(tracts20), aes(fill = incomeContext)) +
scale_fill_manual(values = c("#25CB10", "#FA7800"), name="Income Context") +
labs(title = "Income Context") +
mapTheme() + theme(legend.position="bottom"))
st_drop_geometry(bothRegressions) %>%
group_by(Regression, sale_price) %>%
summarize(mean.MAPE = mean(sale_price.APE, na.rm = TRUE), .groups = "drop") %>%
ungroup() %>%
left_join(philly.test, by = c(#有问题"Name" = "neighborhood")) %>%
st_sf() %>%
ggplot() +
geom_sf(aes(fill = mean.MAPE)) +
geom_sf(data = bothRegressions, colour = "black", size = 0.5) +
facet_wrap(~Regression) +
scale_fill_gradient(low = palette5[1], high = palette5[5],
name = "MAPE") +
labs(title = "Mean test set MAPE by neighborhood") +
mapTheme()
# You can set some global options for knitting chunks
knitr::opts_chunk$set(echo = TRUE)
# Load some libraries
library(tidyverse)
library(tidycensus)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(broom)
library(tufte)
library(rmarkdown)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
# functions and data directory
root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
livingReg <- lm(sale_price ~ total_livable_area, data = philly_sub_200k)
summary(livingReg)
ggscatter(philly_sub_200k,
x = "total_livable_area",
y = "sale_price",
add = "reg.line") +
stat_cor(aes(label = paste(..rr.label.., ..p.label.., sep = "~`,`~")), label.y = 2500000) +
stat_regline_equation(label.y = 2250000)
# You can set some global options for knitting chunks
knitr::opts_chunk$set(echo = TRUE)
# Load some libraries
library(tidyverse)
library(tidycensus)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(broom)
library(tufte)
library(rmarkdown)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
# functions and data directory
root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
philadelphia311.sf <- read.csv('https://phl.carto.com/api/v2/sql?filename=public_cases_fc&format=csv&skipfields=cartodb_id,the_geom,the_geom_webmercator&q=SELECT%20*%20FROM%20public_cases_fc%20WHERE%20requested_datetime%20%3E=%20%272022-01-01%27%20AND%20requested_datetime%20%3C%20%272023-01-01%27') %>%
dplyr::select(lat, lon) %>%
na.omit() %>%
st_as_sf(coords = c("lon", "lat"), crs = 4326, agr = "constant") %>%
st_transform('ESRI:102729')%>%
distinct()
philadelphia311.sf <- read.csv('https://phl.carto.com/api/v2/sql?filename=public_cases_fc&format=csv&skipfields=cartodb_id,the_geom,the_geom_webmercator&q=SELECT%20*%20FROM%20public_cases_fc%20WHERE%20requested_datetime%20%3E=%20%272022-01-01%27%20AND%20requested_datetime%20%3C%20%272023-01-01%27') %>%
dplyr::select(lat, lon) %>%
na.omit() %>%
st_as_sf(coords = c("lon", "lat"), crs = 4326, agr = "constant") %>%
st_transform('ESRI:102729')%>%
distinct()
philadelphia311.sf <- read.csv('https://phl.carto.com/api/v2/sql?filename=public_cases_fc&format=csv&skipfields=cartodb_id,the_geom,the_geom_webmercator&q=SELECT%20*%20FROM%20public_cases_fc%20WHERE%20requested_datetime%20%3E=%20%272022-01-01%27%20AND%20requested_datetime%20%3C%20%272023-01-01%27') %>%
dplyr::select(lat, lon) %>%
na.omit() %>%
st_as_sf(coords = c("lon", "lat"), crs = 4326, agr = "constant") %>%
st_transform('ESRI:102729')%>%
distinct()
